{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21tn81VWgjiF",
        "outputId": "0788c6d9-0c69-401e-b213-a6ba264c7d3d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKw4PWTBgvvb"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# load in labels and samples for the training subset\n",
        "training_samples_file = open('/content/drive/MyDrive/Mignot Lab Research/Experiments/one_sample/raw_data/training_samples.pkl', 'rb')\n",
        "training_labels_file = open('/content/drive/MyDrive/Mignot Lab Research/Experiments/one_sample/raw_data/training_labels.pkl', 'rb')\n",
        "\n",
        "# load in labels and samples for the test subset\n",
        "test_samples_file = open('/content/drive/MyDrive/Mignot Lab Research/Experiments/one_sample/raw_data/test_samples.pkl', 'rb')\n",
        "test_labels_file = open('/content/drive/MyDrive/Mignot Lab Research/Experiments/one_sample/raw_data/test_labels.pkl', 'rb')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiidlCDHhE03"
      },
      "source": [
        "# training\n",
        "X = pickle.load(training_samples_file)\n",
        "y = pickle.load(training_labels_file)\n",
        "\n",
        "# test\n",
        "test_samples = pickle.load(test_samples_file)\n",
        "test_labels = pickle.load(test_labels_file)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq2uSJ4xhKeO"
      },
      "source": [
        "# convert X to Numpy array since I forgot to in training data preprocessing \n",
        "import numpy as np \n",
        "X = np.array(X)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXCxDrRKhOJK"
      },
      "source": [
        "input_shape=(128, 431)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcqvWlABhuVN"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "model = keras.Sequential()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhlxnQlWh69f"
      },
      "source": [
        "model.add(keras.layers.LSTM(64, input_shape=(128, 431), return_sequences=True))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "536XA1aoiSaW"
      },
      "source": [
        "model.add(keras.layers.LSTM(64))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R72GuUk9iiZ6"
      },
      "source": [
        "model.add(keras.layers.Dense(64, activation='relu'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IDYG3T0ixLG"
      },
      "source": [
        "model.add(keras.layers.Dropout(0.3))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DgkIJUJi2Hq"
      },
      "source": [
        "model.add(keras.layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKvHSRSVi8Am",
        "outputId": "7d97baa5-af4b-4f68-a9a4-453d41f21b1c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128, 64)           126976    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 164,290\n",
            "Trainable params: 164,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnOdEIUoi-Zs"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl-btp5LjTk1",
        "outputId": "b07af2c9-f95a-48fe-c333-80a7fe65c998"
      },
      "source": [
        "history = model.fit(X, y, epochs=250)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "92/92 [==============================] - 3s 14ms/step - loss: 0.3628 - accuracy: 0.9189\n",
            "Epoch 2/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1804 - accuracy: 0.9579\n",
            "Epoch 3/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1242 - accuracy: 0.9622\n",
            "Epoch 4/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1435 - accuracy: 0.9641\n",
            "Epoch 5/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1400 - accuracy: 0.9518\n",
            "Epoch 6/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1508 - accuracy: 0.9578\n",
            "Epoch 7/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1340 - accuracy: 0.9653\n",
            "Epoch 8/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1452 - accuracy: 0.9590\n",
            "Epoch 9/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1522 - accuracy: 0.9644\n",
            "Epoch 10/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1468 - accuracy: 0.9656\n",
            "Epoch 11/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1776 - accuracy: 0.9576\n",
            "Epoch 12/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1745 - accuracy: 0.9578\n",
            "Epoch 13/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1660 - accuracy: 0.9609\n",
            "Epoch 14/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1505 - accuracy: 0.9602\n",
            "Epoch 15/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1270 - accuracy: 0.9547\n",
            "Epoch 16/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1391 - accuracy: 0.9539\n",
            "Epoch 17/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1070 - accuracy: 0.9646\n",
            "Epoch 18/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1271 - accuracy: 0.9559\n",
            "Epoch 19/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1131 - accuracy: 0.9599\n",
            "Epoch 20/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0983 - accuracy: 0.9684\n",
            "Epoch 21/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0925 - accuracy: 0.9711\n",
            "Epoch 22/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1184 - accuracy: 0.9630\n",
            "Epoch 23/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1363 - accuracy: 0.9456\n",
            "Epoch 24/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1768 - accuracy: 0.9024\n",
            "Epoch 25/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1367 - accuracy: 0.9286\n",
            "Epoch 26/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1516 - accuracy: 0.9424\n",
            "Epoch 27/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1089 - accuracy: 0.9637\n",
            "Epoch 28/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1201 - accuracy: 0.9537\n",
            "Epoch 29/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1146 - accuracy: 0.9575\n",
            "Epoch 30/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0895 - accuracy: 0.9726\n",
            "Epoch 31/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0922 - accuracy: 0.9698\n",
            "Epoch 32/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1138 - accuracy: 0.9660\n",
            "Epoch 33/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0831 - accuracy: 0.9797\n",
            "Epoch 34/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0864 - accuracy: 0.9733\n",
            "Epoch 35/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0802 - accuracy: 0.9743\n",
            "Epoch 36/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0863 - accuracy: 0.9732\n",
            "Epoch 37/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0633 - accuracy: 0.9783\n",
            "Epoch 38/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0891 - accuracy: 0.9665\n",
            "Epoch 39/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0895 - accuracy: 0.9612\n",
            "Epoch 40/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0751 - accuracy: 0.9670\n",
            "Epoch 41/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0740 - accuracy: 0.9710\n",
            "Epoch 42/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0908 - accuracy: 0.9652\n",
            "Epoch 43/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1443 - accuracy: 0.9603\n",
            "Epoch 44/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0887 - accuracy: 0.9691\n",
            "Epoch 45/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0623 - accuracy: 0.9770\n",
            "Epoch 46/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0850 - accuracy: 0.9659\n",
            "Epoch 47/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0724 - accuracy: 0.9791\n",
            "Epoch 48/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0706 - accuracy: 0.9786\n",
            "Epoch 49/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0651 - accuracy: 0.9792\n",
            "Epoch 50/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0736 - accuracy: 0.9743\n",
            "Epoch 51/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0701 - accuracy: 0.9827\n",
            "Epoch 52/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0750 - accuracy: 0.9739\n",
            "Epoch 53/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0891 - accuracy: 0.9670\n",
            "Epoch 54/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0994 - accuracy: 0.9633\n",
            "Epoch 55/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1057 - accuracy: 0.9457\n",
            "Epoch 56/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0793 - accuracy: 0.9674\n",
            "Epoch 57/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0689 - accuracy: 0.9738\n",
            "Epoch 58/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0551 - accuracy: 0.9789\n",
            "Epoch 59/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0569 - accuracy: 0.9807\n",
            "Epoch 60/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0563 - accuracy: 0.9821\n",
            "Epoch 61/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0493 - accuracy: 0.9824\n",
            "Epoch 62/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0556 - accuracy: 0.9798\n",
            "Epoch 63/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0631 - accuracy: 0.9802\n",
            "Epoch 64/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0546 - accuracy: 0.9836\n",
            "Epoch 65/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0525 - accuracy: 0.9833\n",
            "Epoch 66/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0712 - accuracy: 0.9775\n",
            "Epoch 67/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0634 - accuracy: 0.9774\n",
            "Epoch 68/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0732 - accuracy: 0.9822\n",
            "Epoch 69/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0734 - accuracy: 0.9800\n",
            "Epoch 70/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0573 - accuracy: 0.9815\n",
            "Epoch 71/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0583 - accuracy: 0.9826\n",
            "Epoch 72/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0638 - accuracy: 0.9809\n",
            "Epoch 73/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0587 - accuracy: 0.9833\n",
            "Epoch 74/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0600 - accuracy: 0.9869\n",
            "Epoch 75/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0642 - accuracy: 0.9838\n",
            "Epoch 76/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0668 - accuracy: 0.9836\n",
            "Epoch 77/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0428 - accuracy: 0.9901\n",
            "Epoch 78/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0631 - accuracy: 0.9776\n",
            "Epoch 79/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0609 - accuracy: 0.9790\n",
            "Epoch 80/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0457 - accuracy: 0.9902\n",
            "Epoch 81/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0558 - accuracy: 0.9883\n",
            "Epoch 82/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0554 - accuracy: 0.9835\n",
            "Epoch 83/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0440 - accuracy: 0.9883\n",
            "Epoch 84/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0310 - accuracy: 0.9933\n",
            "Epoch 85/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0380 - accuracy: 0.9928\n",
            "Epoch 86/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0348 - accuracy: 0.9923\n",
            "Epoch 87/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0726 - accuracy: 0.9797\n",
            "Epoch 88/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1001 - accuracy: 0.9779\n",
            "Epoch 89/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1792 - accuracy: 0.9590\n",
            "Epoch 90/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1363 - accuracy: 0.9686\n",
            "Epoch 91/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0841 - accuracy: 0.9840\n",
            "Epoch 92/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0882 - accuracy: 0.9748\n",
            "Epoch 93/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0783 - accuracy: 0.9811\n",
            "Epoch 94/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0597 - accuracy: 0.9829\n",
            "Epoch 95/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0457 - accuracy: 0.9898\n",
            "Epoch 96/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0466 - accuracy: 0.9907\n",
            "Epoch 97/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0539 - accuracy: 0.9882\n",
            "Epoch 98/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0528 - accuracy: 0.9899\n",
            "Epoch 99/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0471 - accuracy: 0.9896\n",
            "Epoch 100/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0488 - accuracy: 0.9911\n",
            "Epoch 101/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0327 - accuracy: 0.9948\n",
            "Epoch 102/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0373 - accuracy: 0.9921\n",
            "Epoch 103/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1045 - accuracy: 0.9778\n",
            "Epoch 104/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1049 - accuracy: 0.9782\n",
            "Epoch 105/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0968 - accuracy: 0.9818\n",
            "Epoch 106/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0836 - accuracy: 0.9835\n",
            "Epoch 107/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0784 - accuracy: 0.9852\n",
            "Epoch 108/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0893 - accuracy: 0.9822\n",
            "Epoch 109/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0947 - accuracy: 0.9817\n",
            "Epoch 110/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0845 - accuracy: 0.9836\n",
            "Epoch 111/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0792 - accuracy: 0.9853\n",
            "Epoch 112/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0725 - accuracy: 0.9862\n",
            "Epoch 113/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0757 - accuracy: 0.9849\n",
            "Epoch 114/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1129 - accuracy: 0.9723\n",
            "Epoch 115/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1136 - accuracy: 0.9718\n",
            "Epoch 116/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0982 - accuracy: 0.9726\n",
            "Epoch 117/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0875 - accuracy: 0.9809\n",
            "Epoch 118/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0929 - accuracy: 0.9823\n",
            "Epoch 119/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0877 - accuracy: 0.9824\n",
            "Epoch 120/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0927 - accuracy: 0.9822\n",
            "Epoch 121/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0718 - accuracy: 0.9871\n",
            "Epoch 122/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0653 - accuracy: 0.9884\n",
            "Epoch 123/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0916 - accuracy: 0.9821\n",
            "Epoch 124/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0741 - accuracy: 0.9860\n",
            "Epoch 125/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0871 - accuracy: 0.9832\n",
            "Epoch 126/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0761 - accuracy: 0.9849\n",
            "Epoch 127/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0725 - accuracy: 0.9861\n",
            "Epoch 128/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0565 - accuracy: 0.9896\n",
            "Epoch 129/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0744 - accuracy: 0.9859\n",
            "Epoch 130/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0881 - accuracy: 0.9827\n",
            "Epoch 131/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0818 - accuracy: 0.9843\n",
            "Epoch 132/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0688 - accuracy: 0.9872\n",
            "Epoch 133/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0616 - accuracy: 0.9890\n",
            "Epoch 134/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0664 - accuracy: 0.9880\n",
            "Epoch 135/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0763 - accuracy: 0.9857\n",
            "Epoch 136/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0709 - accuracy: 0.9871\n",
            "Epoch 137/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0953 - accuracy: 0.9817\n",
            "Epoch 138/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0718 - accuracy: 0.9867\n",
            "Epoch 139/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0909 - accuracy: 0.9823\n",
            "Epoch 140/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0744 - accuracy: 0.9857\n",
            "Epoch 141/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0699 - accuracy: 0.9870\n",
            "Epoch 142/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0712 - accuracy: 0.9866\n",
            "Epoch 143/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0815 - accuracy: 0.9849\n",
            "Epoch 144/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0885 - accuracy: 0.9832\n",
            "Epoch 145/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0687 - accuracy: 0.9871\n",
            "Epoch 146/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0831 - accuracy: 0.9839\n",
            "Epoch 147/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0814 - accuracy: 0.9846\n",
            "Epoch 148/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0635 - accuracy: 0.9886\n",
            "Epoch 149/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0942 - accuracy: 0.9809\n",
            "Epoch 150/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0683 - accuracy: 0.9879\n",
            "Epoch 151/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0665 - accuracy: 0.9872\n",
            "Epoch 152/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1351 - accuracy: 0.9693\n",
            "Epoch 153/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0855 - accuracy: 0.9829\n",
            "Epoch 154/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0783 - accuracy: 0.9836\n",
            "Epoch 155/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0745 - accuracy: 0.9852\n",
            "Epoch 156/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0804 - accuracy: 0.9828\n",
            "Epoch 157/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0711 - accuracy: 0.9830\n",
            "Epoch 158/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1004 - accuracy: 0.9801\n",
            "Epoch 159/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0627 - accuracy: 0.9889\n",
            "Epoch 160/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0844 - accuracy: 0.9822\n",
            "Epoch 161/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0848 - accuracy: 0.9845\n",
            "Epoch 162/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0549 - accuracy: 0.9906\n",
            "Epoch 163/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0618 - accuracy: 0.9873\n",
            "Epoch 164/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.1005 - accuracy: 0.9770\n",
            "Epoch 165/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0909 - accuracy: 0.9798\n",
            "Epoch 166/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0486 - accuracy: 0.9914\n",
            "Epoch 167/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0494 - accuracy: 0.9882\n",
            "Epoch 168/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0428 - accuracy: 0.9887\n",
            "Epoch 169/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0566 - accuracy: 0.9874\n",
            "Epoch 170/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0395 - accuracy: 0.9930\n",
            "Epoch 171/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0372 - accuracy: 0.9919\n",
            "Epoch 172/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0702 - accuracy: 0.9790\n",
            "Epoch 173/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1182 - accuracy: 0.9669\n",
            "Epoch 174/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0763 - accuracy: 0.9785\n",
            "Epoch 175/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0729 - accuracy: 0.9831\n",
            "Epoch 176/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0765 - accuracy: 0.9799\n",
            "Epoch 177/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0427 - accuracy: 0.9875\n",
            "Epoch 178/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0447 - accuracy: 0.9896\n",
            "Epoch 179/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0409 - accuracy: 0.9877\n",
            "Epoch 180/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0435 - accuracy: 0.9903\n",
            "Epoch 181/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0379 - accuracy: 0.9928\n",
            "Epoch 182/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0294 - accuracy: 0.9942\n",
            "Epoch 183/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0190 - accuracy: 0.9959\n",
            "Epoch 184/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0395 - accuracy: 0.9922\n",
            "Epoch 185/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0336 - accuracy: 0.9921\n",
            "Epoch 186/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0287 - accuracy: 0.9946\n",
            "Epoch 187/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0279 - accuracy: 0.9937\n",
            "Epoch 188/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0205 - accuracy: 0.9972\n",
            "Epoch 189/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0303 - accuracy: 0.9948\n",
            "Epoch 190/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0265 - accuracy: 0.9935\n",
            "Epoch 191/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0226 - accuracy: 0.9967\n",
            "Epoch 192/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0131 - accuracy: 0.9983\n",
            "Epoch 193/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0181 - accuracy: 0.9961\n",
            "Epoch 194/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0315 - accuracy: 0.9932\n",
            "Epoch 195/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0420 - accuracy: 0.9897\n",
            "Epoch 196/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0231 - accuracy: 0.9966\n",
            "Epoch 197/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0251 - accuracy: 0.9965\n",
            "Epoch 198/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0160 - accuracy: 0.9980\n",
            "Epoch 199/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0291 - accuracy: 0.9932\n",
            "Epoch 200/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0231 - accuracy: 0.9951\n",
            "Epoch 201/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0241 - accuracy: 0.9963\n",
            "Epoch 202/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0243 - accuracy: 0.9966\n",
            "Epoch 203/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0195 - accuracy: 0.9974\n",
            "Epoch 204/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0234 - accuracy: 0.9959\n",
            "Epoch 205/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0317 - accuracy: 0.9951\n",
            "Epoch 206/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0257 - accuracy: 0.9959\n",
            "Epoch 207/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0379 - accuracy: 0.9891\n",
            "Epoch 208/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0220 - accuracy: 0.9955\n",
            "Epoch 209/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0307 - accuracy: 0.9924\n",
            "Epoch 210/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0203 - accuracy: 0.9955\n",
            "Epoch 211/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0199 - accuracy: 0.9974\n",
            "Epoch 212/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0170 - accuracy: 0.9978\n",
            "Epoch 213/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0181 - accuracy: 0.9975\n",
            "Epoch 214/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0229 - accuracy: 0.9970\n",
            "Epoch 215/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0116 - accuracy: 0.9987\n",
            "Epoch 216/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0241 - accuracy: 0.9968\n",
            "Epoch 217/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0223 - accuracy: 0.9971\n",
            "Epoch 218/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0177 - accuracy: 0.9977\n",
            "Epoch 219/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0202 - accuracy: 0.9969\n",
            "Epoch 220/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0266 - accuracy: 0.9961\n",
            "Epoch 221/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0236 - accuracy: 0.9966\n",
            "Epoch 222/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0212 - accuracy: 0.9971\n",
            "Epoch 223/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0255 - accuracy: 0.9957\n",
            "Epoch 224/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0314 - accuracy: 0.9954\n",
            "Epoch 225/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0114 - accuracy: 0.9984\n",
            "Epoch 226/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0134 - accuracy: 0.9984\n",
            "Epoch 227/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0233 - accuracy: 0.9965\n",
            "Epoch 228/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0223 - accuracy: 0.9968\n",
            "Epoch 229/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0185 - accuracy: 0.9971\n",
            "Epoch 230/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0298 - accuracy: 0.9960\n",
            "Epoch 231/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0157 - accuracy: 0.9980\n",
            "Epoch 232/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0171 - accuracy: 0.9977\n",
            "Epoch 233/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0520 - accuracy: 0.9901\n",
            "Epoch 234/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0629 - accuracy: 0.9848\n",
            "Epoch 235/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0464 - accuracy: 0.9910\n",
            "Epoch 236/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0416 - accuracy: 0.9901\n",
            "Epoch 237/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0403 - accuracy: 0.9910\n",
            "Epoch 238/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0380 - accuracy: 0.9934\n",
            "Epoch 239/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0489 - accuracy: 0.9908\n",
            "Epoch 240/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0267 - accuracy: 0.9932\n",
            "Epoch 241/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0289 - accuracy: 0.9958\n",
            "Epoch 242/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0249 - accuracy: 0.9952\n",
            "Epoch 243/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0305 - accuracy: 0.9940\n",
            "Epoch 244/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0184 - accuracy: 0.9961\n",
            "Epoch 245/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0187 - accuracy: 0.9974\n",
            "Epoch 246/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0223 - accuracy: 0.9971\n",
            "Epoch 247/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0289 - accuracy: 0.9959\n",
            "Epoch 248/250\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.0163 - accuracy: 0.9977\n",
            "Epoch 249/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0282 - accuracy: 0.9960\n",
            "Epoch 250/250\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 0.0255 - accuracy: 0.9958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZnSPS81kVqH",
        "outputId": "836e88b5-d519-4b11-e015-402f4a607035"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_samples,  test_labels, verbose=2)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 - 1s - loss: 0.3702 - accuracy: 0.9448\n",
            "Test accuracy: 0.9447852969169617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsqeQMgNkXwV",
        "outputId": "865b28cb-d4ef-4671-fd42-2cdd33c08c04"
      },
      "source": [
        "predictions = model.predict_classes(test_samples) # generates a list of predictions"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ7G99pekd4o",
        "outputId": "8c1815a4-b33a-4d5d-b1a8-1b82012927d2"
      },
      "source": [
        "print(\"Test labels: \\n\", test_labels)\n",
        "print(\"Test predictions: \\n\", predictions)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test labels: \n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Test predictions: \n",
            " [0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFI8TTX4kg45"
      },
      "source": [
        "correct = 0\n",
        "for i in range(len(predictions)):\n",
        "  if predictions[i] == test_labels[i]:\n",
        "    correct += 1"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZH4BrAJklWz",
        "outputId": "561f4b85-7cac-4857-e770-6e4eb6ba0f2a"
      },
      "source": [
        "predictions_accuracy = correct/len(test_labels)\n",
        "predictions_accuracy"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9447852760736196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anJ6zmPSknsJ",
        "outputId": "fbe0bedf-75e4-430d-8fcd-d222708b1caa"
      },
      "source": [
        "print(\"The accuracy is: \" + str(round(predictions_accuracy * 100, 1)) + \"%\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is: 94.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQbTADibkqVr"
      },
      "source": [
        "speech_correct = 0\n",
        "for i in range(len(test_labels[:33])):\n",
        "    if predictions[i] == test_labels[i]:\n",
        "      speech_correct += 1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVM-6MzjkvFa",
        "outputId": "6c189098-e897-4505-9a64-8f410b93625e"
      },
      "source": [
        "speech_correct/len(test_labels[:33])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}